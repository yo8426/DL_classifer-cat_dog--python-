{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qfxEcmozgZ1"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import zipfile\n",
        "\n",
        "# local_zip = '/content/drive/MyDrive/image/cats_and_dogs_filtered.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# zip_ref.extractall('/content/drive/MyDrive/image/cats_dogs')\n",
        "# zip_ref.close()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCfq_6sI_K_P"
      },
      "outputs": [],
      "source": [
        "# '/content/drive/MyDrive/image/cats_dogs/cats_dogs_filtered/train/cats'\n",
        "# '/content/drive/MyDrive/image/cats_dogs/cats_dogs_filtered/train/dogs'\n",
        "# '/content/drive/MyDrive/image/cats_dogs/cats_dogs_filtered/validation/cats'\n",
        "# '/content/drive/MyDrive/image/cats_dogs/cats_dogs_filtered/validation/dogs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdfns2x8_pzO"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOFb_ei-ES4w"
      },
      "outputs": [],
      "source": [
        "train_photo = list()\n",
        "train_label = list()\n",
        "validation_photo = list()\n",
        "validation_label = list()\n",
        "for file in glob.glob(f\"/content/drive/MyDrive/image/cats_dogs/cats_and_dogs_filtered/train/dogs/*\"):\n",
        "    output = 1.0\n",
        "    photo=load_img(file,grayscale=True,target_size=(150, 150))\n",
        "    photo = img_to_array(photo)\n",
        "    \n",
        "    train_photo.append(photo)\n",
        "    train_label.append(output)\n",
        "\n",
        "for file in glob.glob(f\"/content/drive/MyDrive/image/cats_dogs/cats_and_dogs_filtered/train/cats/*\"):\n",
        "    output = 0.0\n",
        "    photo=load_img(file,grayscale=True,target_size=(150, 150))\n",
        "    photo = img_to_array(photo)\n",
        "    \n",
        "    train_photo.append(photo)\n",
        "    train_label.append(output)\n",
        "train_photo = np.asarray(train_photo)\n",
        "train_label = np.asarray(train_label)\n",
        "print(train_photo.shape)\n",
        "print(train_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file in glob.glob(f\"/content/drive/MyDrive/image/cats_dogs/cats_and_dogs_filtered/validation/dogs/*\"):\n",
        "    output = 1.0\n",
        "    photo=load_img(file,grayscale=True,target_size=(150, 150))\n",
        "    photo = img_to_array(photo)\n",
        "    \n",
        "    validation_photo.append(photo)\n",
        "    validation_label.append(output)\n",
        "\n",
        "for file in glob.glob(f\"/content/drive/MyDrive/image/cats_dogs/cats_and_dogs_filtered/validation/cats/*\"):\n",
        "    output = 0.0\n",
        "    photo=load_img(file,grayscale=True,target_size=(150, 150))\n",
        "    photo = img_to_array(photo)\n",
        "    \n",
        "    validation_photo.append(photo)\n",
        "    validation_label.append(output)\n",
        "validation_photo = np.asarray(validation_photo)\n",
        "validation_label = np.asarray(validation_label)\n",
        "print(validation_photo.shape)\n",
        "print(validation_label.shape)"
      ],
      "metadata": {
        "id": "2SQHKJXYaZBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels=len(np.unique(train_label))\n",
        "train_label=to_categorical(train_label)\n",
        "from keras.layers import normalization\n",
        "image_size=train_photo.shape[1]\n",
        "train_photo=np.reshape(train_photo,[-1,image_size,image_size,1])\n",
        "validation_photo=np.reshape(validation_photo,[-1,image_size,image_size,1])\n",
        "train_photo=train_photo.astype('float32')/255\n",
        "validation_photo=validation_photo.astype('float32')/255\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_photo, train_label, test_size=0.33, random_state=42)\n",
        "\n",
        "input_shape=(image_size,image_size,1)\n",
        "batch_size=200\n",
        "kernel_size=3\n",
        "pool_size=2\n",
        "filters=64\n",
        "dropout=0.5"
      ],
      "metadata": {
        "id": "Esr7f7aBa8Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(filters=filters, \n",
        "                  kernel_size=kernel_size, \n",
        "                  activation='relu',\n",
        "                  input_shape=input_shape,\n",
        "                  padding='same'))\n",
        "model.add(Conv2D(filters=filters, \n",
        "                  kernel_size=kernel_size, \n",
        "                  activation='relu',\n",
        "                  input_shape=input_shape,\n",
        "                  padding='same'\n",
        "                  ))\n",
        "#model.add(normalization.BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size))\n",
        "model.add(Conv2D(filters=filters*2, \n",
        "                  kernel_size=kernel_size, \n",
        "                  activation='relu',\n",
        "                  input_shape=input_shape,\n",
        "                  padding='same'\n",
        "                  ))\n",
        "model.add(Conv2D(filters=filters*2, \n",
        "                  kernel_size=kernel_size, \n",
        "                  activation='relu',\n",
        "                  input_shape=input_shape,\n",
        "                  padding='same'\n",
        "                  ))\n",
        "#model.add(normalization.BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train,y_train,epochs=50,batch_size=batch_size)\n",
        "loss,acc=model.evaluate(X_test,y_test,batch_size=batch_size)\n",
        "print(\"\\naccuracy:%.1f%%\\n\"%(100.0*acc))"
      ],
      "metadata": {
        "id": "iMJCsTPobsy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = np.argmax(model.predict(validation_photo), axis=-1)\n",
        "\n",
        "import pandas as pd\n",
        "confussion_matrix=pd.crosstab(validation_label,prediction,rownames=['label'],colnames=['predict'])\n",
        "print(confussion_matrix)\n",
        "print(\"prediction accuracy:\",sum(prediction==validation_label)/len(validation_label))"
      ],
      "metadata": {
        "id": "2djAiNnTbiMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AEnS1EeYHq2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "id": "wHg-c6uxLo2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NqoiWSIQ4dX0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "類神經_20220503.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}